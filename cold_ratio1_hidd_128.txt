nohup: ignoring input
Training log will be saved to: runs/20250508_001331_team/training_log.log
Run directory: runs/20250508_001331_team
Train years: [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
Test years:  [2016, 2017, 2018, 2019]
Device: cuda:2
Current run arguments saved to runs/20250508_001331_team/current_run_args.txt
Starting training from epoch 1 to 800.
[00:14:20] Epoch 001  Loss: 2.9390  L_pred:2.9251  L_time:0.0279    train.py:203
           Loss:2.9390                                                          
[00:15:09] Epoch 002  Loss: 2.9314  L_pred:2.9191  L_time:0.0247    train.py:203
           Loss:2.9314                                                          
[00:15:58] Epoch 003  Loss: 2.9244  L_pred:2.9134  L_time:0.0221    train.py:203
           Loss:2.9244                                                          
[00:16:48] Epoch 004  Loss: 2.9179  L_pred:2.9078  L_time:0.0201    train.py:203
           Loss:2.9179                                                          
[00:17:38] Epoch 005  Loss: 2.9117  L_pred:2.9024  L_time:0.0186    train.py:203
           Loss:2.9117                                                          
[00:18:29] Epoch 006  Loss: 2.9058  L_pred:2.8971  L_time:0.0175    train.py:203
           Loss:2.9058                                                          
[00:19:19] Epoch 007  Loss: 2.9003  L_pred:2.8918  L_time:0.0170    train.py:203
           Loss:2.9003                                                          
[00:20:10] Epoch 008  Loss: 2.8948  L_pred:2.8865  L_time:0.0167    train.py:203
           Loss:2.8948                                                          
[00:21:00] Epoch 009  Loss: 2.8894  L_pred:2.8810  L_time:0.0168    train.py:203
           Loss:2.8894                                                          
[00:21:50] Epoch 010  Loss: 2.8845  L_pred:2.8758  L_time:0.0173    train.py:203
           Loss:2.8845                                                          
[00:22:40] Epoch 011  Loss: 2.8805  L_pred:2.8714  L_time:0.0182    train.py:203
           Loss:2.8805                                                          
[00:23:31] Epoch 012  Loss: 2.8765  L_pred:2.8673  L_time:0.0184    train.py:203
           Loss:2.8765                                                          
[00:24:21] Epoch 013  Loss: 2.8726  L_pred:2.8635  L_time:0.0182    train.py:203
           Loss:2.8726                                                          
[00:25:11] Epoch 014  Loss: 2.8686  L_pred:2.8597  L_time:0.0177    train.py:203
           Loss:2.8686                                                          
[00:26:02] Epoch 015  Loss: 2.8645  L_pred:2.8560  L_time:0.0170    train.py:203
           Loss:2.8645                                                          
[00:26:52] Epoch 016  Loss: 2.8606  L_pred:2.8525  L_time:0.0163    train.py:203
           Loss:2.8606                                                          
[00:27:43] Epoch 017  Loss: 2.8567  L_pred:2.8489  L_time:0.0155    train.py:203
           Loss:2.8567                                                          
[00:28:33] Epoch 018  Loss: 2.8528  L_pred:2.8453  L_time:0.0151    train.py:203
           Loss:2.8528                                                          
[00:29:24] Epoch 019  Loss: 2.8488  L_pred:2.8414  L_time:0.0148    train.py:203
           Loss:2.8488                                                          
[00:30:14] Epoch 020  Loss: 2.8447  L_pred:2.8372  L_time:0.0150    train.py:203
           Loss:2.8447                                                          
[00:31:04] Epoch 021  Loss: 2.8405  L_pred:2.8327  L_time:0.0156    train.py:203
           Loss:2.8405                                                          
[00:31:55] Epoch 022  Loss: 2.8362  L_pred:2.8280  L_time:0.0165    train.py:203
           Loss:2.8362                                                          
[00:32:46] Epoch 023  Loss: 2.8322  L_pred:2.8232  L_time:0.0181    train.py:203
           Loss:2.8322                                                          
[00:33:36] Epoch 024  Loss: 2.8283  L_pred:2.8185  L_time:0.0195    train.py:203
           Loss:2.8283                                                          
[00:34:26] Epoch 025  Loss: 2.8248  L_pred:2.8145  L_time:0.0206    train.py:203
           Loss:2.8248                                                          
Eval Epoch 025 (team) MALE [0.4627077579498291, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.5631482601165771, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch025_male0_0.4627_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch025_male0.4627_team.pt (MALE: 0.4627 
at epoch 25)
[00:40:59] Epoch 026  Loss: 2.8214  L_pred:2.8112  L_time:0.0204    train.py:203
           Loss:2.8214                                                          
[00:41:49] Epoch 027  Loss: 2.8184  L_pred:2.8088  L_time:0.0192    train.py:203
           Loss:2.8184                                                          
[00:42:40] Epoch 028  Loss: 2.8157  L_pred:2.8072  L_time:0.0170    train.py:203
           Loss:2.8157                                                          
[00:43:30] Epoch 029  Loss: 2.8134  L_pred:2.8061  L_time:0.0146    train.py:203
           Loss:2.8134                                                          
[00:44:21] Epoch 030  Loss: 2.8112  L_pred:2.8052  L_time:0.0120    train.py:203
           Loss:2.8112                                                          
[00:45:11] Epoch 031  Loss: 2.8096  L_pred:2.8047  L_time:0.0099    train.py:203
           Loss:2.8096                                                          
[00:46:01] Epoch 032  Loss: 2.8083  L_pred:2.8042  L_time:0.0082    train.py:203
           Loss:2.8083                                                          
[00:46:52] Epoch 033  Loss: 2.8073  L_pred:2.8038  L_time:0.0068    train.py:203
           Loss:2.8073                                                          
[00:47:42] Epoch 034  Loss: 2.8064  L_pred:2.8034  L_time:0.0059    train.py:203
           Loss:2.8064                                                          
[00:48:32] Epoch 035  Loss: 2.8056  L_pred:2.8030  L_time:0.0052    train.py:203
           Loss:2.8056                                                          
[00:49:23] Epoch 036  Loss: 2.8051  L_pred:2.8028  L_time:0.0046    train.py:203
           Loss:2.8051                                                          
[00:50:13] Epoch 037  Loss: 2.8043  L_pred:2.8023  L_time:0.0041    train.py:203
           Loss:2.8043                                                          
[00:51:03] Epoch 038  Loss: 2.8038  L_pred:2.8019  L_time:0.0037    train.py:203
           Loss:2.8038                                                          
[00:51:53] Epoch 039  Loss: 2.8033  L_pred:2.8016  L_time:0.0035    train.py:203
           Loss:2.8033                                                          
[00:52:43] Epoch 040  Loss: 2.8029  L_pred:2.8013  L_time:0.0031    train.py:203
           Loss:2.8029                                                          
[00:53:34] Epoch 041  Loss: 2.8024  L_pred:2.8009  L_time:0.0029    train.py:203
           Loss:2.8024                                                          
[00:54:24] Epoch 042  Loss: 2.8018  L_pred:2.8005  L_time:0.0025    train.py:203
           Loss:2.8018                                                          
[00:55:15] Epoch 043  Loss: 2.8016  L_pred:2.8004  L_time:0.0024    train.py:203
           Loss:2.8016                                                          
[00:56:05] Epoch 044  Loss: 2.8013  L_pred:2.8001  L_time:0.0024    train.py:203
           Loss:2.8013                                                          
[00:56:56] Epoch 045  Loss: 2.8011  L_pred:2.7998  L_time:0.0025    train.py:203
           Loss:2.8011                                                          
[00:57:46] Epoch 046  Loss: 2.8008  L_pred:2.7994  L_time:0.0028    train.py:203
           Loss:2.8008                                                          
[00:58:37] Epoch 047  Loss: 2.8005  L_pred:2.7991  L_time:0.0028    train.py:203
           Loss:2.8005                                                          
[00:59:27] Epoch 048  Loss: 2.8006  L_pred:2.7992  L_time:0.0027    train.py:203
           Loss:2.8006                                                          
[01:00:18] Epoch 049  Loss: 2.8003  L_pred:2.7990  L_time:0.0025    train.py:203
           Loss:2.8003                                                          
[01:01:08] Epoch 050  Loss: 2.8000  L_pred:2.7988  L_time:0.0025    train.py:203
           Loss:2.8000                                                          
Eval Epoch 050 (team) MALE [0.5046061277389526, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.5829131603240967, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch050_male0_0.5046_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[01:07:41] Epoch 051  Loss: 2.7998  L_pred:2.7985  L_time:0.0026    train.py:203
           Loss:2.7998                                                          
[01:08:31] Epoch 052  Loss: 2.7996  L_pred:2.7982  L_time:0.0028    train.py:203
           Loss:2.7996                                                          
[01:09:22] Epoch 053  Loss: 2.7992  L_pred:2.7978  L_time:0.0029    train.py:203
           Loss:2.7992                                                          
[01:10:12] Epoch 054  Loss: 2.7990  L_pred:2.7976  L_time:0.0030    train.py:203
           Loss:2.7990                                                          
[01:11:02] Epoch 055  Loss: 2.7989  L_pred:2.7975  L_time:0.0028    train.py:203
           Loss:2.7989                                                          
[01:11:52] Epoch 056  Loss: 2.7988  L_pred:2.7975  L_time:0.0026    train.py:203
           Loss:2.7988                                                          
[01:12:43] Epoch 057  Loss: 2.7985  L_pred:2.7972  L_time:0.0027    train.py:203
           Loss:2.7985                                                          
[01:13:33] Epoch 058  Loss: 2.7985  L_pred:2.7971  L_time:0.0028    train.py:203
           Loss:2.7985                                                          
[01:14:23] Epoch 059  Loss: 2.7982  L_pred:2.7968  L_time:0.0028    train.py:203
           Loss:2.7982                                                          
[01:15:14] Epoch 060  Loss: 2.7980  L_pred:2.7967  L_time:0.0027    train.py:203
           Loss:2.7980                                                          
[01:16:04] Epoch 061  Loss: 2.7977  L_pred:2.7964  L_time:0.0025    train.py:203
           Loss:2.7977                                                          
[01:16:55] Epoch 062  Loss: 2.7975  L_pred:2.7963  L_time:0.0025    train.py:203
           Loss:2.7975                                                          
[01:17:45] Epoch 063  Loss: 2.7973  L_pred:2.7960  L_time:0.0025    train.py:203
           Loss:2.7973                                                          
[01:18:35] Epoch 064  Loss: 2.7970  L_pred:2.7957  L_time:0.0026    train.py:203
           Loss:2.7970                                                          
[01:19:26] Epoch 065  Loss: 2.7969  L_pred:2.7956  L_time:0.0025    train.py:203
           Loss:2.7969                                                          
[01:20:16] Epoch 066  Loss: 2.7965  L_pred:2.7953  L_time:0.0025    train.py:203
           Loss:2.7965                                                          
[01:21:07] Epoch 067  Loss: 2.7964  L_pred:2.7951  L_time:0.0025    train.py:203
           Loss:2.7964                                                          
[01:21:57] Epoch 068  Loss: 2.7959  L_pred:2.7947  L_time:0.0025    train.py:203
           Loss:2.7959                                                          
[01:22:48] Epoch 069  Loss: 2.7957  L_pred:2.7944  L_time:0.0025    train.py:203
           Loss:2.7957                                                          
[01:23:38] Epoch 070  Loss: 2.7953  L_pred:2.7941  L_time:0.0025    train.py:203
           Loss:2.7953                                                          
[01:24:29] Epoch 071  Loss: 2.7952  L_pred:2.7940  L_time:0.0026    train.py:203
           Loss:2.7952                                                          
[01:25:20] Epoch 072  Loss: 2.7949  L_pred:2.7936  L_time:0.0026    train.py:203
           Loss:2.7949                                                          
[01:26:10] Epoch 073  Loss: 2.7945  L_pred:2.7932  L_time:0.0026    train.py:203
           Loss:2.7945                                                          
[01:27:01] Epoch 074  Loss: 2.7943  L_pred:2.7929  L_time:0.0027    train.py:203
           Loss:2.7943                                                          
[01:27:51] Epoch 075  Loss: 2.7939  L_pred:2.7926  L_time:0.0026    train.py:203
           Loss:2.7939                                                          
Eval Epoch 075 (team) MALE [0.48019248247146606, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.5533454418182373, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch075_male0_0.4802_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[01:34:22] Epoch 076  Loss: 2.7938  L_pred:2.7924  L_time:0.0027    train.py:203
           Loss:2.7938                                                          
[01:35:13] Epoch 077  Loss: 2.7935  L_pred:2.7922  L_time:0.0026    train.py:203
           Loss:2.7935                                                          
[01:36:03] Epoch 078  Loss: 2.7934  L_pred:2.7921  L_time:0.0026    train.py:203
           Loss:2.7934                                                          
[01:36:54] Epoch 079  Loss: 2.7930  L_pred:2.7918  L_time:0.0026    train.py:203
           Loss:2.7930                                                          
[01:37:45] Epoch 080  Loss: 2.7928  L_pred:2.7916  L_time:0.0023    train.py:203
           Loss:2.7928                                                          
[01:38:35] Epoch 081  Loss: 2.7926  L_pred:2.7914  L_time:0.0025    train.py:203
           Loss:2.7926                                                          
[01:39:26] Epoch 082  Loss: 2.7922  L_pred:2.7911  L_time:0.0022    train.py:203
           Loss:2.7922                                                          
[01:40:16] Epoch 083  Loss: 2.7918  L_pred:2.7907  L_time:0.0023    train.py:203
           Loss:2.7918                                                          
[01:41:07] Epoch 084  Loss: 2.7917  L_pred:2.7905  L_time:0.0025    train.py:203
           Loss:2.7917                                                          
[01:41:57] Epoch 085  Loss: 2.7915  L_pred:2.7905  L_time:0.0021    train.py:203
           Loss:2.7915                                                          
[01:42:47] Epoch 086  Loss: 2.7912  L_pred:2.7900  L_time:0.0024    train.py:203
           Loss:2.7912                                                          
[01:43:38] Epoch 087  Loss: 2.7909  L_pred:2.7897  L_time:0.0024    train.py:203
           Loss:2.7909                                                          
[01:44:28] Epoch 088  Loss: 2.7910  L_pred:2.7899  L_time:0.0022    train.py:203
           Loss:2.7910                                                          
[01:45:19] Epoch 089  Loss: 2.7906  L_pred:2.7893  L_time:0.0025    train.py:203
           Loss:2.7906                                                          
[01:46:09] Epoch 090  Loss: 2.7904  L_pred:2.7892  L_time:0.0023    train.py:203
           Loss:2.7904                                                          
[01:47:00] Epoch 091  Loss: 2.7901  L_pred:2.7890  L_time:0.0022    train.py:203
           Loss:2.7901                                                          
[01:47:51] Epoch 092  Loss: 2.7902  L_pred:2.7890  L_time:0.0026    train.py:203
           Loss:2.7902                                                          
[01:48:41] Epoch 093  Loss: 2.7897  L_pred:2.7887  L_time:0.0020    train.py:203
           Loss:2.7897                                                          
[01:49:31] Epoch 094  Loss: 2.7892  L_pred:2.7882  L_time:0.0021    train.py:203
           Loss:2.7892                                                          
[01:50:21] Epoch 095  Loss: 2.7895  L_pred:2.7883  L_time:0.0024    train.py:203
           Loss:2.7895                                                          
[01:51:11] Epoch 096  Loss: 2.7890  L_pred:2.7881  L_time:0.0018    train.py:203
           Loss:2.7890                                                          
[01:52:01] Epoch 097  Loss: 2.7889  L_pred:2.7879  L_time:0.0019    train.py:203
           Loss:2.7889                                                          
[01:52:51] Epoch 098  Loss: 2.7887  L_pred:2.7876  L_time:0.0023    train.py:203
           Loss:2.7887                                                          
[01:53:41] Epoch 099  Loss: 2.7881  L_pred:2.7871  L_time:0.0020    train.py:203
           Loss:2.7881                                                          
[01:54:31] Epoch 100  Loss: 2.7883  L_pred:2.7875  L_time:0.0017    train.py:203
           Loss:2.7883                                                          
Eval Epoch 100 (team) MALE [0.4651332497596741, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.5343505144119263, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch100_male0_0.4651_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[02:01:03] Epoch 101  Loss: 2.7878  L_pred:2.7868  L_time:0.0020    train.py:203
           Loss:2.7878                                                          
[02:01:54] Epoch 102  Loss: 2.7877  L_pred:2.7867  L_time:0.0021    train.py:203
           Loss:2.7877                                                          
[02:02:44] Epoch 103  Loss: 2.7876  L_pred:2.7867  L_time:0.0017    train.py:203
           Loss:2.7876                                                          
[02:03:35] Epoch 104  Loss: 2.7873  L_pred:2.7864  L_time:0.0017    train.py:203
           Loss:2.7873                                                          
[02:04:25] Epoch 105  Loss: 2.7872  L_pred:2.7862  L_time:0.0020    train.py:203
           Loss:2.7872                                                          
[02:05:16] Epoch 106  Loss: 2.7867  L_pred:2.7858  L_time:0.0019    train.py:203
           Loss:2.7867                                                          
[02:06:06] Epoch 107  Loss: 2.7870  L_pred:2.7862  L_time:0.0016    train.py:203
           Loss:2.7870                                                          
[02:06:57] Epoch 108  Loss: 2.7863  L_pred:2.7854  L_time:0.0018    train.py:203
           Loss:2.7863                                                          
[02:07:47] Epoch 109  Loss: 2.7862  L_pred:2.7853  L_time:0.0019    train.py:203
           Loss:2.7862                                                          
[02:08:37] Epoch 110  Loss: 2.7861  L_pred:2.7852  L_time:0.0016    train.py:203
           Loss:2.7861                                                          
[02:09:27] Epoch 111  Loss: 2.7858  L_pred:2.7849  L_time:0.0017    train.py:203
           Loss:2.7858                                                          
[02:10:18] Epoch 112  Loss: 2.7856  L_pred:2.7847  L_time:0.0018    train.py:203
           Loss:2.7856                                                          
[02:11:08] Epoch 113  Loss: 2.7854  L_pred:2.7846  L_time:0.0016    train.py:203
           Loss:2.7854                                                          
[02:11:58] Epoch 114  Loss: 2.7850  L_pred:2.7842  L_time:0.0016    train.py:203
           Loss:2.7850                                                          
[02:12:49] Epoch 115  Loss: 2.7850  L_pred:2.7841  L_time:0.0017    train.py:203
           Loss:2.7850                                                          
[02:13:39] Epoch 116  Loss: 2.7846  L_pred:2.7839  L_time:0.0015    train.py:203
           Loss:2.7846                                                          
[02:14:29] Epoch 117  Loss: 2.7843  L_pred:2.7835  L_time:0.0016    train.py:203
           Loss:2.7843                                                          
[02:15:19] Epoch 118  Loss: 2.7843  L_pred:2.7835  L_time:0.0017    train.py:203
           Loss:2.7843                                                          
[02:16:09] Epoch 119  Loss: 2.7841  L_pred:2.7833  L_time:0.0014    train.py:203
           Loss:2.7841                                                          
[02:16:59] Epoch 120  Loss: 2.7836  L_pred:2.7828  L_time:0.0016    train.py:203
           Loss:2.7836                                                          
[02:17:49] Epoch 121  Loss: 2.7834  L_pred:2.7826  L_time:0.0016    train.py:203
           Loss:2.7834                                                          
[02:18:39] Epoch 122  Loss: 2.7835  L_pred:2.7827  L_time:0.0015    train.py:203
           Loss:2.7835                                                          
[02:19:30] Epoch 123  Loss: 2.7829  L_pred:2.7821  L_time:0.0015    train.py:203
           Loss:2.7829                                                          
[02:20:20] Epoch 124  Loss: 2.7827  L_pred:2.7819  L_time:0.0015    train.py:203
           Loss:2.7827                                                          
[02:21:10] Epoch 125  Loss: 2.7826  L_pred:2.7819  L_time:0.0013    train.py:203
           Loss:2.7826                                                          
Eval Epoch 125 (team) MALE [0.45466741919517517, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.5223995447158813, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch125_male0_0.4547_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch025_male0.4627_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch125_male0.4547_team.pt (MALE: 0.4547 
at epoch 125)
[02:27:37] Epoch 126  Loss: 2.7825  L_pred:2.7817  L_time:0.0015    train.py:203
           Loss:2.7825                                                          
[02:28:28] Epoch 127  Loss: 2.7820  L_pred:2.7814  L_time:0.0013    train.py:203
           Loss:2.7820                                                          
[02:29:18] Epoch 128  Loss: 2.7815  L_pred:2.7808  L_time:0.0014    train.py:203
           Loss:2.7815                                                          
[02:30:09] Epoch 129  Loss: 2.7814  L_pred:2.7806  L_time:0.0014    train.py:203
           Loss:2.7814                                                          
[02:30:59] Epoch 130  Loss: 2.7812  L_pred:2.7806  L_time:0.0013    train.py:203
           Loss:2.7812                                                          
[02:31:49] Epoch 131  Loss: 2.7812  L_pred:2.7804  L_time:0.0015    train.py:203
           Loss:2.7812                                                          
[02:32:39] Epoch 132  Loss: 2.7810  L_pred:2.7804  L_time:0.0012    train.py:203
           Loss:2.7810                                                          
[02:33:29] Epoch 133  Loss: 2.7806  L_pred:2.7799  L_time:0.0014    train.py:203
           Loss:2.7806                                                          
[02:34:19] Epoch 134  Loss: 2.7803  L_pred:2.7797  L_time:0.0013    train.py:203
           Loss:2.7803                                                          
[02:35:10] Epoch 135  Loss: 2.7800  L_pred:2.7793  L_time:0.0013    train.py:203
           Loss:2.7800                                                          
[02:36:00] Epoch 136  Loss: 2.7798  L_pred:2.7791  L_time:0.0014    train.py:203
           Loss:2.7798                                                          
[02:36:51] Epoch 137  Loss: 2.7796  L_pred:2.7790  L_time:0.0013    train.py:203
           Loss:2.7796                                                          
[02:37:41] Epoch 138  Loss: 2.7793  L_pred:2.7786  L_time:0.0014    train.py:203
           Loss:2.7793                                                          
[02:38:32] Epoch 139  Loss: 2.7797  L_pred:2.7791  L_time:0.0012    train.py:203
           Loss:2.7797                                                          
[02:39:23] Epoch 140  Loss: 2.7798  L_pred:2.7790  L_time:0.0014    train.py:203
           Loss:2.7798                                                          
[02:40:13] Epoch 141  Loss: 2.7797  L_pred:2.7792  L_time:0.0011    train.py:203
           Loss:2.7797                                                          
[02:41:04] Epoch 142  Loss: 2.7785  L_pred:2.7779  L_time:0.0013    train.py:203
           Loss:2.7785                                                          
[02:41:54] Epoch 143  Loss: 2.7785  L_pred:2.7779  L_time:0.0013    train.py:203
           Loss:2.7785                                                          
[02:42:45] Epoch 144  Loss: 2.7791  L_pred:2.7786  L_time:0.0011    train.py:203
           Loss:2.7791                                                          
[02:43:35] Epoch 145  Loss: 2.7783  L_pred:2.7776  L_time:0.0013    train.py:203
           Loss:2.7783                                                          
[02:44:26] Epoch 146  Loss: 2.7777  L_pred:2.7771  L_time:0.0013    train.py:203
           Loss:2.7777                                                          
[02:45:16] Epoch 147  Loss: 2.7779  L_pred:2.7773  L_time:0.0012    train.py:203
           Loss:2.7779                                                          
[02:46:07] Epoch 148  Loss: 2.7774  L_pred:2.7767  L_time:0.0014    train.py:203
           Loss:2.7774                                                          
[02:46:57] Epoch 149  Loss: 2.7768  L_pred:2.7762  L_time:0.0012    train.py:203
           Loss:2.7768                                                          
[02:47:47] Epoch 150  Loss: 2.7769  L_pred:2.7763  L_time:0.0012    train.py:203
           Loss:2.7769                                                          
Eval Epoch 150 (team) MALE [0.4412742257118225, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.5087789297103882, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch150_male0_0.4413_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch125_male0.4547_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch150_male0.4413_team.pt (MALE: 0.4413 
at epoch 150)
[02:54:13] Epoch 151  Loss: 2.7767  L_pred:2.7760  L_time:0.0013    train.py:203
           Loss:2.7767                                                          
[02:55:04] Epoch 152  Loss: 2.7765  L_pred:2.7759  L_time:0.0012    train.py:203
           Loss:2.7765                                                          
[02:55:53] Epoch 153  Loss: 2.7763  L_pred:2.7756  L_time:0.0013    train.py:203
           Loss:2.7763                                                          
[02:56:43] Epoch 154  Loss: 2.7759  L_pred:2.7752  L_time:0.0013    train.py:203
           Loss:2.7759                                                          
[02:57:33] Epoch 155  Loss: 2.7759  L_pred:2.7753  L_time:0.0012    train.py:203
           Loss:2.7759                                                          
[02:58:24] Epoch 156  Loss: 2.7757  L_pred:2.7750  L_time:0.0013    train.py:203
           Loss:2.7757                                                          
[02:59:14] Epoch 157  Loss: 2.7755  L_pred:2.7749  L_time:0.0012    train.py:203
           Loss:2.7755                                                          
[03:00:05] Epoch 158  Loss: 2.7752  L_pred:2.7746  L_time:0.0013    train.py:203
           Loss:2.7752                                                          
[03:00:55] Epoch 159  Loss: 2.7749  L_pred:2.7743  L_time:0.0012    train.py:203
           Loss:2.7749                                                          
[03:01:45] Epoch 160  Loss: 2.7747  L_pred:2.7740  L_time:0.0012    train.py:203
           Loss:2.7747                                                          
[03:02:36] Epoch 161  Loss: 2.7746  L_pred:2.7740  L_time:0.0013    train.py:203
           Loss:2.7746                                                          
[03:03:26] Epoch 162  Loss: 2.7745  L_pred:2.7739  L_time:0.0012    train.py:203
           Loss:2.7745                                                          
[03:04:16] Epoch 163  Loss: 2.7744  L_pred:2.7737  L_time:0.0013    train.py:203
           Loss:2.7744                                                          
[03:05:07] Epoch 164  Loss: 2.7746  L_pred:2.7740  L_time:0.0012    train.py:203
           Loss:2.7746                                                          
[03:05:57] Epoch 165  Loss: 2.7739  L_pred:2.7732  L_time:0.0014    train.py:203
           Loss:2.7739                                                          
[03:06:48] Epoch 166  Loss: 2.7736  L_pred:2.7730  L_time:0.0012    train.py:203
           Loss:2.7736                                                          
[03:07:38] Epoch 167  Loss: 2.7734  L_pred:2.7728  L_time:0.0012    train.py:203
           Loss:2.7734                                                          
[03:08:29] Epoch 168  Loss: 2.7735  L_pred:2.7728  L_time:0.0014    train.py:203
           Loss:2.7735                                                          
[03:09:19] Epoch 169  Loss: 2.7736  L_pred:2.7731  L_time:0.0012    train.py:203
           Loss:2.7736                                                          
[03:10:09] Epoch 170  Loss: 2.7729  L_pred:2.7722  L_time:0.0014    train.py:203
           Loss:2.7729                                                          
[03:11:00] Epoch 171  Loss: 2.7725  L_pred:2.7719  L_time:0.0013    train.py:203
           Loss:2.7725                                                          
[03:11:50] Epoch 172  Loss: 2.7726  L_pred:2.7719  L_time:0.0013    train.py:203
           Loss:2.7726                                                          
[03:12:41] Epoch 173  Loss: 2.7722  L_pred:2.7715  L_time:0.0014    train.py:203
           Loss:2.7722                                                          
[03:13:31] Epoch 174  Loss: 2.7722  L_pred:2.7716  L_time:0.0013    train.py:203
           Loss:2.7722                                                          
[03:14:22] Epoch 175  Loss: 2.7718  L_pred:2.7711  L_time:0.0014    train.py:203
           Loss:2.7718                                                          
Eval Epoch 175 (team) MALE [0.4144653081893921, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.4820290207862854, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch175_male0_0.4145_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch150_male0.4413_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch175_male0.4145_team.pt (MALE: 0.4145 
at epoch 175)
[03:20:52] Epoch 176  Loss: 2.7715  L_pred:2.7708  L_time:0.0014    train.py:203
           Loss:2.7715                                                          
[03:21:42] Epoch 177  Loss: 2.7714  L_pred:2.7707  L_time:0.0014    train.py:203
           Loss:2.7714                                                          
[03:22:33] Epoch 178  Loss: 2.7710  L_pred:2.7703  L_time:0.0014    train.py:203
           Loss:2.7710                                                          
[03:23:23] Epoch 179  Loss: 2.7710  L_pred:2.7703  L_time:0.0014    train.py:203
           Loss:2.7710                                                          
[03:24:13] Epoch 180  Loss: 2.7707  L_pred:2.7700  L_time:0.0014    train.py:203
           Loss:2.7707                                                          
[03:25:03] Epoch 181  Loss: 2.7706  L_pred:2.7699  L_time:0.0014    train.py:203
           Loss:2.7706                                                          
[03:25:54] Epoch 182  Loss: 2.7704  L_pred:2.7697  L_time:0.0014    train.py:203
           Loss:2.7704                                                          
[03:26:45] Epoch 183  Loss: 2.7703  L_pred:2.7696  L_time:0.0014    train.py:203
           Loss:2.7703                                                          
[03:27:35] Epoch 184  Loss: 2.7703  L_pred:2.7696  L_time:0.0014    train.py:203
           Loss:2.7703                                                          
[03:28:26] Epoch 185  Loss: 2.7704  L_pred:2.7696  L_time:0.0015    train.py:203
           Loss:2.7704                                                          
[03:29:16] Epoch 186  Loss: 2.7713  L_pred:2.7707  L_time:0.0012    train.py:203
           Loss:2.7713                                                          
[03:30:06] Epoch 187  Loss: 2.7711  L_pred:2.7703  L_time:0.0016    train.py:203
           Loss:2.7711                                                          
[03:30:56] Epoch 188  Loss: 2.7710  L_pred:2.7704  L_time:0.0012    train.py:203
           Loss:2.7710                                                          
[03:31:47] Epoch 189  Loss: 2.7694  L_pred:2.7687  L_time:0.0014    train.py:203
           Loss:2.7694                                                          
[03:32:37] Epoch 190  Loss: 2.7705  L_pred:2.7697  L_time:0.0016    train.py:203
           Loss:2.7705                                                          
[03:33:28] Epoch 191  Loss: 2.7712  L_pred:2.7706  L_time:0.0012    train.py:203
           Loss:2.7712                                                          
[03:34:19] Epoch 192  Loss: 2.7690  L_pred:2.7683  L_time:0.0014    train.py:203
           Loss:2.7690                                                          
[03:35:09] Epoch 193  Loss: 2.7717  L_pred:2.7708  L_time:0.0018    train.py:203
           Loss:2.7717                                                          
[03:35:59] Epoch 194  Loss: 2.7713  L_pred:2.7707  L_time:0.0012    train.py:203
           Loss:2.7713                                                          
[03:36:50] Epoch 195  Loss: 2.7700  L_pred:2.7693  L_time:0.0012    train.py:203
           Loss:2.7700                                                          
[03:37:40] Epoch 196  Loss: 2.7713  L_pred:2.7704  L_time:0.0017    train.py:203
           Loss:2.7713                                                          
[03:38:30] Epoch 197  Loss: 2.7684  L_pred:2.7677  L_time:0.0014    train.py:203
           Loss:2.7684                                                          
[03:39:20] Epoch 198  Loss: 2.7700  L_pred:2.7694  L_time:0.0012    train.py:203
           Loss:2.7700                                                          
[03:40:11] Epoch 199  Loss: 2.7681  L_pred:2.7674  L_time:0.0014    train.py:203
           Loss:2.7681                                                          
[03:41:01] Epoch 200  Loss: 2.7696  L_pred:2.7688  L_time:0.0017    train.py:203
           Loss:2.7696                                                          
Eval Epoch 200 (team) MALE [0.4074714779853821, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.4745330214500427, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch200_male0_0.4075_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch175_male0.4145_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch200_male0.4075_team.pt (MALE: 0.4075 
at epoch 200)
[03:47:28] Epoch 201  Loss: 2.7678  L_pred:2.7671  L_time:0.0014    train.py:203
           Loss:2.7678                                                          
[03:48:18] Epoch 202  Loss: 2.7690  L_pred:2.7683  L_time:0.0013    train.py:203
           Loss:2.7690                                                          
[03:49:08] Epoch 203  Loss: 2.7676  L_pred:2.7669  L_time:0.0015    train.py:203
           Loss:2.7676                                                          
[03:49:58] Epoch 204  Loss: 2.7684  L_pred:2.7676  L_time:0.0017    train.py:203
           Loss:2.7684                                                          
[03:50:48] Epoch 205  Loss: 2.7673  L_pred:2.7666  L_time:0.0015    train.py:203
           Loss:2.7673                                                          
[03:51:39] Epoch 206  Loss: 2.7680  L_pred:2.7673  L_time:0.0013    train.py:203
           Loss:2.7680                                                          
[03:52:29] Epoch 207  Loss: 2.7671  L_pred:2.7664  L_time:0.0015    train.py:203
           Loss:2.7671                                                          
[03:53:19] Epoch 208  Loss: 2.7677  L_pred:2.7668  L_time:0.0016    train.py:203
           Loss:2.7677                                                          
[03:54:09] Epoch 209  Loss: 2.7670  L_pred:2.7662  L_time:0.0015    train.py:203
           Loss:2.7670                                                          
[03:55:00] Epoch 210  Loss: 2.7673  L_pred:2.7666  L_time:0.0014    train.py:203
           Loss:2.7673                                                          
[03:55:50] Epoch 211  Loss: 2.7667  L_pred:2.7660  L_time:0.0015    train.py:203
           Loss:2.7667                                                          
[03:56:40] Epoch 212  Loss: 2.7669  L_pred:2.7661  L_time:0.0015    train.py:203
           Loss:2.7669                                                          
[03:57:30] Epoch 213  Loss: 2.7666  L_pred:2.7659  L_time:0.0014    train.py:203
           Loss:2.7666                                                          
[03:58:21] Epoch 214  Loss: 2.7665  L_pred:2.7658  L_time:0.0014    train.py:203
           Loss:2.7665                                                          
[03:59:11] Epoch 215  Loss: 2.7663  L_pred:2.7656  L_time:0.0015    train.py:203
           Loss:2.7663                                                          
[04:00:01] Epoch 216  Loss: 2.7663  L_pred:2.7656  L_time:0.0015    train.py:203
           Loss:2.7663                                                          
[04:00:51] Epoch 217  Loss: 2.7662  L_pred:2.7655  L_time:0.0014    train.py:203
           Loss:2.7662                                                          
[04:01:41] Epoch 218  Loss: 2.7659  L_pred:2.7652  L_time:0.0014    train.py:203
           Loss:2.7659                                                          
[04:02:31] Epoch 219  Loss: 2.7661  L_pred:2.7653  L_time:0.0015    train.py:203
           Loss:2.7661                                                          
[04:03:21] Epoch 220  Loss: 2.7657  L_pred:2.7650  L_time:0.0014    train.py:203
           Loss:2.7657                                                          
[04:04:12] Epoch 221  Loss: 2.7658  L_pred:2.7651  L_time:0.0014    train.py:203
           Loss:2.7658                                                          
[04:05:02] Epoch 222  Loss: 2.7656  L_pred:2.7649  L_time:0.0015    train.py:203
           Loss:2.7656                                                          
[04:05:53] Epoch 223  Loss: 2.7654  L_pred:2.7646  L_time:0.0015    train.py:203
           Loss:2.7654                                                          
[04:06:43] Epoch 224  Loss: 2.7653  L_pred:2.7646  L_time:0.0014    train.py:203
           Loss:2.7653                                                          
[04:07:33] Epoch 225  Loss: 2.7651  L_pred:2.7644  L_time:0.0014    train.py:203
           Loss:2.7651                                                          
Eval Epoch 225 (team) MALE [0.41405799984931946, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.48211270570755005, 1.1996724605560303, 1.3402553796768188, 
1.3455837965011597, 1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch225_male0_0.4141_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[04:14:00] Epoch 226  Loss: 2.7654  L_pred:2.7646  L_time:0.0015    train.py:203
           Loss:2.7654                                                          
[04:14:50] Epoch 227  Loss: 2.7650  L_pred:2.7643  L_time:0.0014    train.py:203
           Loss:2.7650                                                          
[04:15:40] Epoch 228  Loss: 2.7650  L_pred:2.7643  L_time:0.0014    train.py:203
           Loss:2.7650                                                          
[04:16:31] Epoch 229  Loss: 2.7649  L_pred:2.7641  L_time:0.0015    train.py:203
           Loss:2.7649                                                          
[04:17:21] Epoch 230  Loss: 2.7649  L_pred:2.7642  L_time:0.0014    train.py:203
           Loss:2.7649                                                          
[04:18:11] Epoch 231  Loss: 2.7647  L_pred:2.7640  L_time:0.0014    train.py:203
           Loss:2.7647                                                          
[04:19:01] Epoch 232  Loss: 2.7646  L_pred:2.7639  L_time:0.0014    train.py:203
           Loss:2.7646                                                          
[04:19:51] Epoch 233  Loss: 2.7645  L_pred:2.7637  L_time:0.0015    train.py:203
           Loss:2.7645                                                          
[04:20:42] Epoch 234  Loss: 2.7643  L_pred:2.7636  L_time:0.0014    train.py:203
           Loss:2.7643                                                          
[04:21:32] Epoch 235  Loss: 2.7644  L_pred:2.7637  L_time:0.0014    train.py:203
           Loss:2.7644                                                          
[04:22:23] Epoch 236  Loss: 2.7642  L_pred:2.7635  L_time:0.0014    train.py:203
           Loss:2.7642                                                          
[04:23:13] Epoch 237  Loss: 2.7641  L_pred:2.7634  L_time:0.0014    train.py:203
           Loss:2.7641                                                          
[04:24:04] Epoch 238  Loss: 2.7640  L_pred:2.7633  L_time:0.0014    train.py:203
           Loss:2.7640                                                          
[04:24:54] Epoch 239  Loss: 2.7639  L_pred:2.7632  L_time:0.0014    train.py:203
           Loss:2.7639                                                          
[04:25:44] Epoch 240  Loss: 2.7637  L_pred:2.7629  L_time:0.0014    train.py:203
           Loss:2.7637                                                          
[04:26:35] Epoch 241  Loss: 2.7636  L_pred:2.7629  L_time:0.0014    train.py:203
           Loss:2.7636                                                          
[04:27:25] Epoch 242  Loss: 2.7635  L_pred:2.7628  L_time:0.0014    train.py:203
           Loss:2.7635                                                          
[04:28:16] Epoch 243  Loss: 2.7634  L_pred:2.7627  L_time:0.0014    train.py:203
           Loss:2.7634                                                          
[04:29:06] Epoch 244  Loss: 2.7634  L_pred:2.7627  L_time:0.0013    train.py:203
           Loss:2.7634                                                          
[04:29:57] Epoch 245  Loss: 2.7633  L_pred:2.7626  L_time:0.0013    train.py:203
           Loss:2.7633                                                          
[04:30:47] Epoch 246  Loss: 2.7632  L_pred:2.7625  L_time:0.0014    train.py:203
           Loss:2.7632                                                          
[04:31:38] Epoch 247  Loss: 2.7631  L_pred:2.7625  L_time:0.0013    train.py:203
           Loss:2.7631                                                          
[04:32:28] Epoch 248  Loss: 2.7630  L_pred:2.7623  L_time:0.0014    train.py:203
           Loss:2.7630                                                          
[04:33:19] Epoch 249  Loss: 2.7629  L_pred:2.7622  L_time:0.0014    train.py:203
           Loss:2.7629                                                          
[04:34:10] Epoch 250  Loss: 2.7628  L_pred:2.7621  L_time:0.0013    train.py:203
           Loss:2.7628                                                          
Eval Epoch 250 (team) MALE [0.4063343405723572, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.47428378462791443, 1.1996724605560303, 1.3402553796768188, 
1.3455837965011597, 1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch250_male0_0.4063_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch200_male0.4075_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch250_male0.4063_team.pt (MALE: 0.4063 
at epoch 250)
[04:40:41] Epoch 251  Loss: 2.7627  L_pred:2.7621  L_time:0.0013    train.py:203
           Loss:2.7627                                                          
[04:41:32] Epoch 252  Loss: 2.7626  L_pred:2.7619  L_time:0.0014    train.py:203
           Loss:2.7626                                                          
[04:42:22] Epoch 253  Loss: 2.7625  L_pred:2.7618  L_time:0.0013    train.py:203
           Loss:2.7625                                                          
[04:43:13] Epoch 254  Loss: 2.7624  L_pred:2.7617  L_time:0.0013    train.py:203
           Loss:2.7624                                                          
[04:44:03] Epoch 255  Loss: 2.7623  L_pred:2.7617  L_time:0.0013    train.py:203
           Loss:2.7623                                                          
[04:44:53] Epoch 256  Loss: 2.7623  L_pred:2.7617  L_time:0.0013    train.py:203
           Loss:2.7623                                                          
[04:45:44] Epoch 257  Loss: 2.7621  L_pred:2.7614  L_time:0.0014    train.py:203
           Loss:2.7621                                                          
[04:46:34] Epoch 258  Loss: 2.7621  L_pred:2.7614  L_time:0.0013    train.py:203
           Loss:2.7621                                                          
[04:47:25] Epoch 259  Loss: 2.7619  L_pred:2.7612  L_time:0.0013    train.py:203
           Loss:2.7619                                                          
[04:48:15] Epoch 260  Loss: 2.7619  L_pred:2.7613  L_time:0.0013    train.py:203
           Loss:2.7619                                                          
[04:49:05] Epoch 261  Loss: 2.7618  L_pred:2.7611  L_time:0.0013    train.py:203
           Loss:2.7618                                                          
[04:49:56] Epoch 262  Loss: 2.7617  L_pred:2.7611  L_time:0.0013    train.py:203
           Loss:2.7617                                                          
[04:50:46] Epoch 263  Loss: 2.7615  L_pred:2.7609  L_time:0.0013    train.py:203
           Loss:2.7615                                                          
[04:51:37] Epoch 264  Loss: 2.7616  L_pred:2.7610  L_time:0.0013    train.py:203
           Loss:2.7616                                                          
[04:52:27] Epoch 265  Loss: 2.7613  L_pred:2.7607  L_time:0.0013    train.py:203
           Loss:2.7613                                                          
[04:53:17] Epoch 266  Loss: 2.7613  L_pred:2.7607  L_time:0.0012    train.py:203
           Loss:2.7613                                                          
[04:54:08] Epoch 267  Loss: 2.7612  L_pred:2.7606  L_time:0.0012    train.py:203
           Loss:2.7612                                                          
[04:54:58] Epoch 268  Loss: 2.7611  L_pred:2.7605  L_time:0.0012    train.py:203
           Loss:2.7611                                                          
[04:55:49] Epoch 269  Loss: 2.7612  L_pred:2.7606  L_time:0.0012    train.py:203
           Loss:2.7612                                                          
[04:56:39] Epoch 270  Loss: 2.7610  L_pred:2.7604  L_time:0.0012    train.py:203
           Loss:2.7610                                                          
[04:57:30] Epoch 271  Loss: 2.7609  L_pred:2.7603  L_time:0.0012    train.py:203
           Loss:2.7609                                                          
[04:58:20] Epoch 272  Loss: 2.7609  L_pred:2.7602  L_time:0.0012    train.py:203
           Loss:2.7609                                                          
[04:59:11] Epoch 273  Loss: 2.7607  L_pred:2.7601  L_time:0.0012    train.py:203
           Loss:2.7607                                                          
[05:00:01] Epoch 274  Loss: 2.7606  L_pred:2.7600  L_time:0.0012    train.py:203
           Loss:2.7606                                                          
[05:00:51] Epoch 275  Loss: 2.7606  L_pred:2.7600  L_time:0.0012    train.py:203
           Loss:2.7606                                                          
Eval Epoch 275 (team) MALE [0.3967258334159851, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.4650554656982422, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch275_male0_0.3967_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch250_male0.4063_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch275_male0.3967_team.pt (MALE: 0.3967 
at epoch 275)
[05:07:25] Epoch 276  Loss: 2.7606  L_pred:2.7600  L_time:0.0012    train.py:203
           Loss:2.7606                                                          
[05:08:15] Epoch 277  Loss: 2.7605  L_pred:2.7599  L_time:0.0012    train.py:203
           Loss:2.7605                                                          
[05:09:06] Epoch 278  Loss: 2.7604  L_pred:2.7598  L_time:0.0012    train.py:203
           Loss:2.7604                                                          
[05:09:56] Epoch 279  Loss: 2.7604  L_pred:2.7598  L_time:0.0012    train.py:203
           Loss:2.7604                                                          
[05:10:47] Epoch 280  Loss: 2.7602  L_pred:2.7596  L_time:0.0012    train.py:203
           Loss:2.7602                                                          
[05:11:38] Epoch 281  Loss: 2.7603  L_pred:2.7597  L_time:0.0012    train.py:203
           Loss:2.7603                                                          
[05:12:28] Epoch 282  Loss: 2.7600  L_pred:2.7594  L_time:0.0012    train.py:203
           Loss:2.7600                                                          
[05:13:18] Epoch 283  Loss: 2.7600  L_pred:2.7595  L_time:0.0012    train.py:203
           Loss:2.7600                                                          
[05:14:09] Epoch 284  Loss: 2.7598  L_pred:2.7592  L_time:0.0012    train.py:203
           Loss:2.7598                                                          
[05:14:59] Epoch 285  Loss: 2.7600  L_pred:2.7594  L_time:0.0012    train.py:203
           Loss:2.7600                                                          
[05:15:50] Epoch 286  Loss: 2.7598  L_pred:2.7593  L_time:0.0012    train.py:203
           Loss:2.7598                                                          
[05:16:40] Epoch 287  Loss: 2.7597  L_pred:2.7591  L_time:0.0012    train.py:203
           Loss:2.7597                                                          
[05:17:31] Epoch 288  Loss: 2.7598  L_pred:2.7592  L_time:0.0011    train.py:203
           Loss:2.7598                                                          
[05:18:21] Epoch 289  Loss: 2.7600  L_pred:2.7594  L_time:0.0012    train.py:203
           Loss:2.7600                                                          
[05:19:11] Epoch 290  Loss: 2.7603  L_pred:2.7598  L_time:0.0011    train.py:203
           Loss:2.7603                                                          
[05:20:02] Epoch 291  Loss: 2.7601  L_pred:2.7595  L_time:0.0012    train.py:203
           Loss:2.7601                                                          
[05:20:53] Epoch 292  Loss: 2.7599  L_pred:2.7594  L_time:0.0010    train.py:203
           Loss:2.7599                                                          
[05:21:43] Epoch 293  Loss: 2.7595  L_pred:2.7589  L_time:0.0011    train.py:203
           Loss:2.7595                                                          
[05:22:33] Epoch 294  Loss: 2.7594  L_pred:2.7589  L_time:0.0011    train.py:203
           Loss:2.7594                                                          
[05:23:24] Epoch 295  Loss: 2.7598  L_pred:2.7593  L_time:0.0010    train.py:203
           Loss:2.7598                                                          
[05:24:15] Epoch 296  Loss: 2.7596  L_pred:2.7590  L_time:0.0011    train.py:203
           Loss:2.7596                                                          
[05:25:05] Epoch 297  Loss: 2.7593  L_pred:2.7588  L_time:0.0010    train.py:203
           Loss:2.7593                                                          
[05:25:55] Epoch 298  Loss: 2.7591  L_pred:2.7586  L_time:0.0011    train.py:203
           Loss:2.7591                                                          
[05:26:46] Epoch 299  Loss: 2.7592  L_pred:2.7586  L_time:0.0011    train.py:203
           Loss:2.7592                                                          
[05:27:36] Epoch 300  Loss: 2.7595  L_pred:2.7590  L_time:0.0010    train.py:203
           Loss:2.7595                                                          
Eval Epoch 300 (team) MALE [0.4108444154262543, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.477888286113739, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597, 
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch300_male0_0.4108_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[05:34:04] Epoch 301  Loss: 2.7591  L_pred:2.7585  L_time:0.0011    train.py:203
           Loss:2.7591                                                          
[05:34:54] Epoch 302  Loss: 2.7589  L_pred:2.7584  L_time:0.0010    train.py:203
           Loss:2.7589                                                          
[05:35:44] Epoch 303  Loss: 2.7590  L_pred:2.7585  L_time:0.0010    train.py:203
           Loss:2.7590                                                          
[05:36:34] Epoch 304  Loss: 2.7590  L_pred:2.7585  L_time:0.0011    train.py:203
           Loss:2.7590                                                          
[05:37:25] Epoch 305  Loss: 2.7589  L_pred:2.7584  L_time:0.0010    train.py:203
           Loss:2.7589                                                          
[05:38:15] Epoch 306  Loss: 2.7587  L_pred:2.7582  L_time:0.0010    train.py:203
           Loss:2.7587                                                          
[05:39:05] Epoch 307  Loss: 2.7587  L_pred:2.7581  L_time:0.0011    train.py:203
           Loss:2.7587                                                          
[05:39:55] Epoch 308  Loss: 2.7587  L_pred:2.7582  L_time:0.0010    train.py:203
           Loss:2.7587                                                          
[05:40:46] Epoch 309  Loss: 2.7586  L_pred:2.7581  L_time:0.0010    train.py:203
           Loss:2.7586                                                          
[05:41:36] Epoch 310  Loss: 2.7584  L_pred:2.7579  L_time:0.0010    train.py:203
           Loss:2.7584                                                          
[05:42:26] Epoch 311  Loss: 2.7584  L_pred:2.7579  L_time:0.0010    train.py:203
           Loss:2.7584                                                          
[05:43:16] Epoch 312  Loss: 2.7583  L_pred:2.7578  L_time:0.0010    train.py:203
           Loss:2.7583                                                          
[05:44:06] Epoch 313  Loss: 2.7583  L_pred:2.7578  L_time:0.0010    train.py:203
           Loss:2.7583                                                          
[05:44:57] Epoch 314  Loss: 2.7583  L_pred:2.7578  L_time:0.0010    train.py:203
           Loss:2.7583                                                          
[05:45:47] Epoch 315  Loss: 2.7583  L_pred:2.7578  L_time:0.0010    train.py:203
           Loss:2.7583                                                          
[05:46:38] Epoch 316  Loss: 2.7583  L_pred:2.7578  L_time:0.0010    train.py:203
           Loss:2.7583                                                          
[05:47:27] Epoch 317  Loss: 2.7582  L_pred:2.7577  L_time:0.0010    train.py:203
           Loss:2.7582                                                          
[05:48:18] Epoch 318  Loss: 2.7582  L_pred:2.7577  L_time:0.0010    train.py:203
           Loss:2.7582                                                          
[05:49:08] Epoch 319  Loss: 2.7581  L_pred:2.7576  L_time:0.0010    train.py:203
           Loss:2.7581                                                          
[05:49:59] Epoch 320  Loss: 2.7580  L_pred:2.7575  L_time:0.0009    train.py:203
           Loss:2.7580                                                          
[05:50:49] Epoch 321  Loss: 2.7581  L_pred:2.7576  L_time:0.0010    train.py:203
           Loss:2.7581                                                          
[05:51:39] Epoch 322  Loss: 2.7581  L_pred:2.7576  L_time:0.0009    train.py:203
           Loss:2.7581                                                          
[05:52:29] Epoch 323  Loss: 2.7580  L_pred:2.7575  L_time:0.0010    train.py:203
           Loss:2.7580                                                          
[05:53:19] Epoch 324  Loss: 2.7578  L_pred:2.7574  L_time:0.0009    train.py:203
           Loss:2.7578                                                          
[05:54:09] Epoch 325  Loss: 2.7580  L_pred:2.7575  L_time:0.0010    train.py:203
           Loss:2.7580                                                          
Eval Epoch 325 (team) MALE [0.38979172706604004, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.45705997943878174, 1.1996724605560303, 1.3402553796768188, 
1.3455837965011597, 1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch325_male0_0.3898_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch275_male0.3967_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch325_male0.3898_team.pt (MALE: 0.3898 
at epoch 325)
[06:00:35] Epoch 326  Loss: 2.7578  L_pred:2.7573  L_time:0.0009    train.py:203
           Loss:2.7578                                                          
[06:01:25] Epoch 327  Loss: 2.7577  L_pred:2.7572  L_time:0.0009    train.py:203
           Loss:2.7577                                                          
[06:02:16] Epoch 328  Loss: 2.7577  L_pred:2.7572  L_time:0.0009    train.py:203
           Loss:2.7577                                                          
[06:03:06] Epoch 329  Loss: 2.7577  L_pred:2.7573  L_time:0.0009    train.py:203
           Loss:2.7577                                                          
[06:03:57] Epoch 330  Loss: 2.7578  L_pred:2.7573  L_time:0.0010    train.py:203
           Loss:2.7578                                                          
[06:04:47] Epoch 331  Loss: 2.7579  L_pred:2.7575  L_time:0.0009    train.py:203
           Loss:2.7579                                                          
[06:05:38] Epoch 332  Loss: 2.7578  L_pred:2.7573  L_time:0.0010    train.py:203
           Loss:2.7578                                                          
[06:06:28] Epoch 333  Loss: 2.7577  L_pred:2.7573  L_time:0.0009    train.py:203
           Loss:2.7577                                                          
[06:07:19] Epoch 334  Loss: 2.7575  L_pred:2.7570  L_time:0.0009    train.py:203
           Loss:2.7575                                                          
[06:08:10] Epoch 335  Loss: 2.7575  L_pred:2.7571  L_time:0.0009    train.py:203
           Loss:2.7575                                                          
[06:09:00] Epoch 336  Loss: 2.7576  L_pred:2.7572  L_time:0.0009    train.py:203
           Loss:2.7576                                                          
[06:09:51] Epoch 337  Loss: 2.7576  L_pred:2.7571  L_time:0.0009    train.py:203
           Loss:2.7576                                                          
[06:10:41] Epoch 338  Loss: 2.7576  L_pred:2.7571  L_time:0.0008    train.py:203
           Loss:2.7576                                                          
[06:11:32] Epoch 339  Loss: 2.7574  L_pred:2.7570  L_time:0.0009    train.py:203
           Loss:2.7574                                                          
[06:12:22] Epoch 340  Loss: 2.7573  L_pred:2.7568  L_time:0.0009    train.py:203
           Loss:2.7573                                                          
[06:13:12] Epoch 341  Loss: 2.7573  L_pred:2.7568  L_time:0.0009    train.py:203
           Loss:2.7573                                                          
[06:14:02] Epoch 342  Loss: 2.7573  L_pred:2.7569  L_time:0.0009    train.py:203
           Loss:2.7573                                                          
[06:14:52] Epoch 343  Loss: 2.7573  L_pred:2.7569  L_time:0.0009    train.py:203
           Loss:2.7573                                                          
[06:15:42] Epoch 344  Loss: 2.7572  L_pred:2.7568  L_time:0.0009    train.py:203
           Loss:2.7572                                                          
[06:16:33] Epoch 345  Loss: 2.7571  L_pred:2.7567  L_time:0.0009    train.py:203
           Loss:2.7571                                                          
[06:17:23] Epoch 346  Loss: 2.7571  L_pred:2.7567  L_time:0.0008    train.py:203
           Loss:2.7571                                                          
[06:18:13] Epoch 347  Loss: 2.7571  L_pred:2.7567  L_time:0.0009    train.py:203
           Loss:2.7571                                                          
[06:19:03] Epoch 348  Loss: 2.7571  L_pred:2.7567  L_time:0.0009    train.py:203
           Loss:2.7571                                                          
[06:19:53] Epoch 349  Loss: 2.7572  L_pred:2.7567  L_time:0.0009    train.py:203
           Loss:2.7572                                                          
[06:20:44] Epoch 350  Loss: 2.7570  L_pred:2.7566  L_time:0.0008    train.py:203
           Loss:2.7570                                                          
Eval Epoch 350 (team) MALE [0.4026974141597748, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.4677237272262573, 1.1996724605560303, 1.3402553796768188, 1.3455837965011597,
1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch350_male0_0.4027_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[06:27:13] Epoch 351  Loss: 2.7570  L_pred:2.7566  L_time:0.0009    train.py:203
           Loss:2.7570                                                          
[06:28:04] Epoch 352  Loss: 2.7569  L_pred:2.7565  L_time:0.0008    train.py:203
           Loss:2.7569                                                          
[06:28:54] Epoch 353  Loss: 2.7569  L_pred:2.7564  L_time:0.0008    train.py:203
           Loss:2.7569                                                          
[06:29:44] Epoch 354  Loss: 2.7570  L_pred:2.7566  L_time:0.0009    train.py:203
           Loss:2.7570                                                          
[06:30:34] Epoch 355  Loss: 2.7572  L_pred:2.7568  L_time:0.0008    train.py:203
           Loss:2.7572                                                          
[06:31:25] Epoch 356  Loss: 2.7571  L_pred:2.7567  L_time:0.0009    train.py:203
           Loss:2.7571                                                          
[06:32:16] Epoch 357  Loss: 2.7570  L_pred:2.7566  L_time:0.0008    train.py:203
           Loss:2.7570                                                          
[06:33:06] Epoch 358  Loss: 2.7568  L_pred:2.7564  L_time:0.0008    train.py:203
           Loss:2.7568                                                          
[06:33:57] Epoch 359  Loss: 2.7568  L_pred:2.7564  L_time:0.0008    train.py:203
           Loss:2.7568                                                          
[06:34:47] Epoch 360  Loss: 2.7567  L_pred:2.7563  L_time:0.0008    train.py:203
           Loss:2.7567                                                          
[06:35:38] Epoch 361  Loss: 2.7567  L_pred:2.7563  L_time:0.0008    train.py:203
           Loss:2.7567                                                          
[06:36:29] Epoch 362  Loss: 2.7567  L_pred:2.7564  L_time:0.0008    train.py:203
           Loss:2.7567                                                          
[06:37:20] Epoch 363  Loss: 2.7567  L_pred:2.7562  L_time:0.0008    train.py:203
           Loss:2.7567                                                          
[06:38:10] Epoch 364  Loss: 2.7566  L_pred:2.7562  L_time:0.0008    train.py:203
           Loss:2.7566                                                          
[06:39:01] Epoch 365  Loss: 2.7565  L_pred:2.7561  L_time:0.0008    train.py:203
           Loss:2.7565                                                          
[06:39:52] Epoch 366  Loss: 2.7566  L_pred:2.7562  L_time:0.0008    train.py:203
           Loss:2.7566                                                          
[06:40:43] Epoch 367  Loss: 2.7566  L_pred:2.7562  L_time:0.0008    train.py:203
           Loss:2.7566                                                          
[06:41:33] Epoch 368  Loss: 2.7566  L_pred:2.7562  L_time:0.0008    train.py:203
           Loss:2.7566                                                          
[06:42:24] Epoch 369  Loss: 2.7567  L_pred:2.7564  L_time:0.0007    train.py:203
           Loss:2.7567                                                          
[06:43:14] Epoch 370  Loss: 2.7567  L_pred:2.7563  L_time:0.0008    train.py:203
           Loss:2.7567                                                          
[06:44:05] Epoch 371  Loss: 2.7569  L_pred:2.7566  L_time:0.0008    train.py:203
           Loss:2.7569                                                          
[06:44:56] Epoch 372  Loss: 2.7566  L_pred:2.7562  L_time:0.0008    train.py:203
           Loss:2.7566                                                          
[06:45:46] Epoch 373  Loss: 2.7565  L_pred:2.7561  L_time:0.0007    train.py:203
           Loss:2.7565                                                          
[06:46:37] Epoch 374  Loss: 2.7563  L_pred:2.7559  L_time:0.0008    train.py:203
           Loss:2.7563                                                          
[06:47:27] Epoch 375  Loss: 2.7564  L_pred:2.7560  L_time:0.0008    train.py:203
           Loss:2.7564                                                          
Eval Epoch 375 (team) MALE [0.3743838369846344, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.44115740060806274, 1.1996724605560303, 1.3402553796768188, 
1.3455837965011597, 1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch375_male0_0.3744_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
Removed old best model: 
runs/20250508_001331_team/best_model_epoch325_male0.3898_team.pt
New best model saved: 
runs/20250508_001331_team/best_model_epoch375_male0.3744_team.pt (MALE: 0.3744 
at epoch 375)
[06:53:54] Epoch 376  Loss: 2.7566  L_pred:2.7562  L_time:0.0007    train.py:203
           Loss:2.7566                                                          
[06:54:44] Epoch 377  Loss: 2.7567  L_pred:2.7563  L_time:0.0008    train.py:203
           Loss:2.7567                                                          
[06:55:35] Epoch 378  Loss: 2.7567  L_pred:2.7564  L_time:0.0008    train.py:203
           Loss:2.7567                                                          
[06:56:25] Epoch 379  Loss: 2.7563  L_pred:2.7559  L_time:0.0008    train.py:203
           Loss:2.7563                                                          
[06:57:15] Epoch 380  Loss: 2.7564  L_pred:2.7561  L_time:0.0008    train.py:203
           Loss:2.7564                                                          
[06:58:05] Epoch 381  Loss: 2.7565  L_pred:2.7561  L_time:0.0007    train.py:203
           Loss:2.7565                                                          
[06:58:55] Epoch 382  Loss: 2.7568  L_pred:2.7564  L_time:0.0008    train.py:203
           Loss:2.7568                                                          
[06:59:45] Epoch 383  Loss: 2.7563  L_pred:2.7560  L_time:0.0007    train.py:203
           Loss:2.7563                                                          
[07:00:35] Epoch 384  Loss: 2.7564  L_pred:2.7560  L_time:0.0007    train.py:203
           Loss:2.7564                                                          
[07:01:25] Epoch 385  Loss: 2.7560  L_pred:2.7556  L_time:0.0008    train.py:203
           Loss:2.7560                                                          
[07:02:16] Epoch 386  Loss: 2.7563  L_pred:2.7559  L_time:0.0007    train.py:203
           Loss:2.7563                                                          
[07:03:06] Epoch 387  Loss: 2.7561  L_pred:2.7558  L_time:0.0008    train.py:203
           Loss:2.7561                                                          
[07:03:56] Epoch 388  Loss: 2.7560  L_pred:2.7557  L_time:0.0007    train.py:203
           Loss:2.7560                                                          
[07:04:46] Epoch 389  Loss: 2.7561  L_pred:2.7557  L_time:0.0007    train.py:203
           Loss:2.7561                                                          
[07:05:37] Epoch 390  Loss: 2.7562  L_pred:2.7558  L_time:0.0008    train.py:203
           Loss:2.7562                                                          
[07:06:27] Epoch 391  Loss: 2.7561  L_pred:2.7557  L_time:0.0007    train.py:203
           Loss:2.7561                                                          
[07:07:17] Epoch 392  Loss: 2.7560  L_pred:2.7556  L_time:0.0007    train.py:203
           Loss:2.7560                                                          
[07:08:08] Epoch 393  Loss: 2.7560  L_pred:2.7556  L_time:0.0007    train.py:203
           Loss:2.7560                                                          
[07:08:58] Epoch 394  Loss: 2.7561  L_pred:2.7557  L_time:0.0007    train.py:203
           Loss:2.7561                                                          
[07:09:49] Epoch 395  Loss: 2.7561  L_pred:2.7557  L_time:0.0008    train.py:203
           Loss:2.7561                                                          
[07:10:39] Epoch 396  Loss: 2.7560  L_pred:2.7557  L_time:0.0007    train.py:203
           Loss:2.7560                                                          
[07:11:29] Epoch 397  Loss: 2.7558  L_pred:2.7554  L_time:0.0007    train.py:203
           Loss:2.7558                                                          
[07:12:20] Epoch 398  Loss: 2.7558  L_pred:2.7554  L_time:0.0007    train.py:203
           Loss:2.7558                                                          
[07:13:10] Epoch 399  Loss: 2.7559  L_pred:2.7555  L_time:0.0007    train.py:203
           Loss:2.7559                                                          
[07:14:01] Epoch 400  Loss: 2.7558  L_pred:2.7554  L_time:0.0007    train.py:203
           Loss:2.7558                                                          
Eval Epoch 400 (team) MALE [0.3938867449760437, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.45757389068603516, 1.1996724605560303, 1.3402553796768188, 
1.3455837965011597, 1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch400_male0_0.3939_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[07:20:32] Epoch 401  Loss: 2.7557  L_pred:2.7554  L_time:0.0007    train.py:203
           Loss:2.7557                                                          
[07:21:23] Epoch 402  Loss: 2.7557  L_pred:2.7553  L_time:0.0007    train.py:203
           Loss:2.7557                                                          
[07:22:13] Epoch 403  Loss: 2.7557  L_pred:2.7554  L_time:0.0007    train.py:203
           Loss:2.7557                                                          
[07:23:03] Epoch 404  Loss: 2.7558  L_pred:2.7554  L_time:0.0007    train.py:203
           Loss:2.7558                                                          
[07:23:54] Epoch 405  Loss: 2.7556  L_pred:2.7553  L_time:0.0007    train.py:203
           Loss:2.7556                                                          
[07:24:44] Epoch 406  Loss: 2.7556  L_pred:2.7553  L_time:0.0007    train.py:203
           Loss:2.7556                                                          
[07:25:34] Epoch 407  Loss: 2.7556  L_pred:2.7553  L_time:0.0007    train.py:203
           Loss:2.7556                                                          
[07:26:24] Epoch 408  Loss: 2.7555  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[07:27:15] Epoch 409  Loss: 2.7556  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7556                                                          
[07:28:05] Epoch 410  Loss: 2.7555  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[07:28:56] Epoch 411  Loss: 2.7555  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[07:29:46] Epoch 412  Loss: 2.7555  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[07:30:37] Epoch 413  Loss: 2.7555  L_pred:2.7551  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[07:31:27] Epoch 414  Loss: 2.7555  L_pred:2.7551  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[07:32:17] Epoch 415  Loss: 2.7556  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7556                                                          
[07:33:08] Epoch 416  Loss: 2.7556  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7556                                                          
[07:33:58] Epoch 417  Loss: 2.7555  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[07:34:49] Epoch 418  Loss: 2.7554  L_pred:2.7551  L_time:0.0007    train.py:203
           Loss:2.7554                                                          
[07:35:40] Epoch 419  Loss: 2.7554  L_pred:2.7550  L_time:0.0007    train.py:203
           Loss:2.7554                                                          
[07:36:30] Epoch 420  Loss: 2.7554  L_pred:2.7551  L_time:0.0007    train.py:203
           Loss:2.7554                                                          
[07:37:21] Epoch 421  Loss: 2.7553  L_pred:2.7550  L_time:0.0007    train.py:203
           Loss:2.7553                                                          
[07:38:11] Epoch 422  Loss: 2.7553  L_pred:2.7550  L_time:0.0007    train.py:203
           Loss:2.7553                                                          
[07:39:01] Epoch 423  Loss: 2.7553  L_pred:2.7550  L_time:0.0007    train.py:203
           Loss:2.7553                                                          
[07:39:52] Epoch 424  Loss: 2.7553  L_pred:2.7550  L_time:0.0007    train.py:203
           Loss:2.7553                                                          
[07:40:43] Epoch 425  Loss: 2.7553  L_pred:2.7550  L_time:0.0007    train.py:203
           Loss:2.7553                                                          
Eval Epoch 425 (team) MALE [0.39054855704307556, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.45392510294914246, 1.1996724605560303, 1.3402553796768188, 
1.3455837965011597, 1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch425_male0_0.3905_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[07:47:11] Epoch 426  Loss: 2.7553  L_pred:2.7549  L_time:0.0007    train.py:203
           Loss:2.7553                                                          
[07:48:01] Epoch 427  Loss: 2.7552  L_pred:2.7549  L_time:0.0007    train.py:203
           Loss:2.7552                                                          
[07:48:51] Epoch 428  Loss: 2.7552  L_pred:2.7549  L_time:0.0007    train.py:203
           Loss:2.7552                                                          
[07:49:41] Epoch 429  Loss: 2.7552  L_pred:2.7548  L_time:0.0007    train.py:203
           Loss:2.7552                                                          
[07:50:31] Epoch 430  Loss: 2.7552  L_pred:2.7549  L_time:0.0007    train.py:203
           Loss:2.7552                                                          
[07:51:21] Epoch 431  Loss: 2.7552  L_pred:2.7549  L_time:0.0007    train.py:203
           Loss:2.7552                                                          
[07:52:12] Epoch 432  Loss: 2.7552  L_pred:2.7549  L_time:0.0007    train.py:203
           Loss:2.7552                                                          
[07:53:02] Epoch 433  Loss: 2.7552  L_pred:2.7549  L_time:0.0006    train.py:203
           Loss:2.7552                                                          
[07:53:52] Epoch 434  Loss: 2.7552  L_pred:2.7549  L_time:0.0006    train.py:203
           Loss:2.7552                                                          
[07:54:42] Epoch 435  Loss: 2.7551  L_pred:2.7548  L_time:0.0006    train.py:203
           Loss:2.7551                                                          
[07:55:32] Epoch 436  Loss: 2.7551  L_pred:2.7548  L_time:0.0006    train.py:203
           Loss:2.7551                                                          
[07:56:23] Epoch 437  Loss: 2.7552  L_pred:2.7549  L_time:0.0006    train.py:203
           Loss:2.7552                                                          
[07:57:13] Epoch 438  Loss: 2.7552  L_pred:2.7549  L_time:0.0007    train.py:203
           Loss:2.7552                                                          
[07:58:03] Epoch 439  Loss: 2.7553  L_pred:2.7550  L_time:0.0006    train.py:203
           Loss:2.7553                                                          
[07:58:54] Epoch 440  Loss: 2.7554  L_pred:2.7551  L_time:0.0007    train.py:203
           Loss:2.7554                                                          
[07:59:44] Epoch 441  Loss: 2.7556  L_pred:2.7553  L_time:0.0006    train.py:203
           Loss:2.7556                                                          
[08:00:34] Epoch 442  Loss: 2.7556  L_pred:2.7552  L_time:0.0007    train.py:203
           Loss:2.7556                                                          
[08:01:25] Epoch 443  Loss: 2.7557  L_pred:2.7554  L_time:0.0006    train.py:203
           Loss:2.7557                                                          
[08:02:15] Epoch 444  Loss: 2.7555  L_pred:2.7551  L_time:0.0007    train.py:203
           Loss:2.7555                                                          
[08:03:06] Epoch 445  Loss: 2.7551  L_pred:2.7548  L_time:0.0006    train.py:203
           Loss:2.7551                                                          
[08:03:56] Epoch 446  Loss: 2.7549  L_pred:2.7546  L_time:0.0006    train.py:203
           Loss:2.7549                                                          
[08:04:47] Epoch 447  Loss: 2.7550  L_pred:2.7547  L_time:0.0006    train.py:203
           Loss:2.7550                                                          
[08:05:37] Epoch 448  Loss: 2.7551  L_pred:2.7548  L_time:0.0006    train.py:203
           Loss:2.7551                                                          
[08:06:27] Epoch 449  Loss: 2.7551  L_pred:2.7547  L_time:0.0006    train.py:203
           Loss:2.7551                                                          
[08:07:18] Epoch 450  Loss: 2.7550  L_pred:2.7547  L_time:0.0006    train.py:203
           Loss:2.7550                                                          
Eval Epoch 450 (team) MALE [0.3962351977825165, 0.8730535507202148, 
1.012279987335205, 1.0098925828933716, 0.9849193692207336]  RMSLE 
[0.45810678601264954, 1.1996724605560303, 1.3402553796768188, 
1.3455837965011597, 1.3298697471618652]
Evaluated model checkpoint saved: 
runs/20250508_001331_team/evaluated_model_epoch450_male0_0.3962_male1_0.8731_mal
e2_1.0123_male3_1.0099_male4_0.9849_team.pt
[08:13:46] Epoch 451  Loss: 2.7549  L_pred:2.7546  L_time:0.0006    train.py:203
           Loss:2.7549                                                          
[08:14:36] Epoch 452  Loss: 2.7549  L_pred:2.7546  L_time:0.0006    train.py:203
           Loss:2.7549                                                          
[08:15:26] Epoch 453  Loss: 2.7549  L_pred:2.7546  L_time:0.0006    train.py:203
           Loss:2.7549                                                          
[08:16:16] Epoch 454  Loss: 2.7550  L_pred:2.7547  L_time:0.0006    train.py:203
           Loss:2.7550                                                          
[08:17:06] Epoch 455  Loss: 2.7550  L_pred:2.7547  L_time:0.0006    train.py:203
           Loss:2.7550                                                          
[08:17:56] Epoch 456  Loss: 2.7550  L_pred:2.7547  L_time:0.0006    train.py:203
           Loss:2.7550                                                          
[08:18:46] Epoch 457  Loss: 2.7550  L_pred:2.7547  L_time:0.0006    train.py:203
           Loss:2.7550                                                          
[08:19:36] Epoch 458  Loss: 2.7549  L_pred:2.7546  L_time:0.0006    train.py:203
           Loss:2.7549                                                          
[08:20:26] Epoch 459  Loss: 2.7548  L_pred:2.7545  L_time:0.0006    train.py:203
           Loss:2.7548                                                          
[08:21:15] Epoch 460  Loss: 2.7548  L_pred:2.7545  L_time:0.0006    train.py:203
           Loss:2.7548                                                          
[08:22:05] Epoch 461  Loss: 2.7548  L_pred:2.7545  L_time:0.0006    train.py:203
           Loss:2.7548                                                          
[08:22:55] Epoch 462  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
[08:23:46] Epoch 463  Loss: 2.7548  L_pred:2.7545  L_time:0.0006    train.py:203
           Loss:2.7548                                                          
[08:24:36] Epoch 464  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
[08:25:27] Epoch 465  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
[08:26:17] Epoch 466  Loss: 2.7548  L_pred:2.7545  L_time:0.0006    train.py:203
           Loss:2.7548                                                          
[08:27:08] Epoch 467  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
[08:27:59] Epoch 468  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
[08:28:49] Epoch 469  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
[08:29:39] Epoch 470  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
[08:30:30] Epoch 471  Loss: 2.7547  L_pred:2.7544  L_time:0.0006    train.py:203
           Loss:2.7547                                                          
